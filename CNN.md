##CNN卷积神经网络

参考：https://www.zhihu.com/question/39022858

### 1、卷积层

![img](https://pic1.zhimg.com/50/v2-f9dab2820dc8a941e62c1e5c63e418f1_hd.gif) 

通过设定权值矩阵，对原有图像进行卷积，从而达到压缩图片获取放大图片信息的作用

####步长（stride）和边界（padding）的概念

像我们在上面看到的一样，过滤器或者说权值矩阵，在整个图像范围内一次移动一个像素。我们可以把它定义成一个超参数（hyperparameter），从而来表示我们想让权值矩阵在图像内如何移动。如果权值矩阵一次移动一个像素，我们称其步长为 1。下面我们看一下步长为 2 时的情况。

<img src="https://pic4.zhimg.com/50/v2-2d5ce7b1af041dab1b4019cc2776b71b_hd.gif" data-rawwidth="421" data-rawheight="150" data-thumbnail="https://pic4.zhimg.com/50/v2-2d5ce7b1af041dab1b4019cc2776b71b_hd.jpg" class="origin_image zh-lightbox-thumb" width="421" data-original="https://pic4.zhimg.com/v2-2d5ce7b1af041dab1b4019cc2776b71b_r.jpg">

你可以看见当我们增加步长值的时候，图像的规格持续变小。在输入图像四周填充 0 边界可以解决这个问题。我们也可以在高步长值的情况下在图像四周填加不只一层的 0 边界。

我们可以看见在我们给图像填加一层 0 边界后，图像的原始形状是如何被保持的。由于输出图像和输入图像是大小相同的，所以这被称为 same padding。

![img](https://pic4.zhimg.com/50/v2-19f50c58341de1d5c4700972a718b8e1_hd.gif) 

这就是 same padding（意味着我们仅考虑输入图像的有效像素）。中间的 4*4 像素是相同的。这里我们已经利用边界保留了更多信息，并且也已经保留了图像的原大小。

#### **多过滤与激活图** 

需要记住的是权值的纵深维度（depth dimension）和输入图像的纵深维度是相同的。权值会延伸到输入图像的整个深度。因此，和一个单一权值矩阵进行卷积会产生一个单一纵深维度的卷积化输出。大多数情况下都不使用单一过滤器（权值矩阵），而是应用维度相同的多个过滤器。

每一个过滤器的输出被堆叠在一起，形成卷积图像的纵深维度。假设我们有一个 32x32x3 的输入。我们使用 5x5x3，带有 valid padding 的 10 个过滤器。输出的维度将会是 28x28x10。

激活图是卷积层的输出。 

### 2、池化层（可选）

有时图像太大，我们需要减少训练参数的数量，它被要求在随后的卷积层之间周期性地引进池化层。池化的唯一目的是减少图像的空间大小。池化在每一个纵深维度上独自完成，因此图像的纵深保持不变。池化层的最常见形式是最大池化。 

![img](https://pic1.zhimg.com/80/v2-cae74f34159e48d581156d80e8e12ec6_hd.jpg)

在这里，我们把步幅定为 2，池化尺寸也为 2。最大化执行也应用在每个卷机输出的深度尺寸中。正如你所看到的，最大池化操作后，4x4 卷积的输出变成了 2x2。

####输出维度

理解每个卷积层输入和输出的尺寸可能会有点难度。以下三点或许可以让你了解输出尺寸的问题。有三个超参数可以控制输出卷的大小。

1. 过滤器数量-输出卷的深度与过滤器的数量成正比。请记住该如何堆叠每个过滤器的输出以形成激活映射。激活图的深度等于过滤器的数量。
2. 步幅（Stride）-如果步幅是 1，那么我们处理图片的精细度就进入单像素级别了。更高的步幅意味着同时处理更多的像素，从而产生较小的输出量。
3. 零填充（zero padding）-这有助于我们保留输入图像的尺寸。如果添加了单零填充，则单步幅过滤器的运动会保持在原图尺寸。

我们可以应用一个简单的公式来计算输出尺寸。输出图像的空间尺寸可以计算为**`（[W-F + 2P] / S）+1`**。在这里，W 是输入尺寸，F 是过滤器的尺寸，P 是填充数量，S 是步幅数字。假如我们有一张 32x32x3 的输入图像，我们使用 10 个尺寸为 3x3x3 的过滤器，单步幅和零填充。

那么 W=32，F=3，P=0，S=1。输出深度等于应用的滤波器的数量，即 10，输出尺寸大小为 ([32-3+0]/1)+1 = 30。因此输出尺寸是 30x30x10。

###3、输出层

在多层卷积和填充后，我们需要以类的形式输出。卷积和池化层只会提取特征，并减少原始图像带来的参数。然而，为了生成最终的输出，我们需要应用**全连接层**来生成一个等于我们需要的类的数量的输出。仅仅依靠卷积层是难以达到这个要求的。卷积层可以生成 3D 激活图，而我们只需要图像是否属于一个特定的类这样的内容。**输出层具有类似分类交叉熵的损失函数，用于计算预测误差。一旦前向传播完成，反向传播就会开始更新权重与偏差，以减少误差和损失。**

###4、小结

正如你所看到的，CNN 由不同的卷积层和池化层组成。让我们看看整个网络是什么样子：

<img src="https://pic3.zhimg.com/50/v2-a182b75112c9c6d60892a95f47359d24_hd.jpg" data-rawwidth="640" data-rawheight="188" class="origin_image zh-lightbox-thumb" width="640" data-original="https://pic3.zhimg.com/v2-a182b75112c9c6d60892a95f47359d24_r.jpg">![img](https://pic3.zhimg.com/80/v2-a182b75112c9c6d60892a95f47359d24_hd.jpg)

- 我们将输入图像传递到第一个卷积层中，卷积后以激活图形式输出。图片在卷积层中过滤后的特征会被输出，并传递下去。
- 每个过滤器都会给出不同的特征，以帮助进行正确的类预测。因为我们需要保证图像大小的一致，所以我们使用同样的填充（零填充），否则填充会被使用，因为它可以帮助减少特征的数量。
- 随后加入池化层进一步减少参数的数量。
- 在预测最终提出前，数据会经过多个卷积和池化层的处理。卷积层会帮助提取特征，越深的卷积神经网络会提取越具体的特征，越浅的网络提取越浅显的特征。
- 如前所述，CNN 中的输出层是全连接层，其中来自其他层的输入在这里被平化和发送，以便将输出转换为网络所需的参数。
- 随后输出层会产生输出，这些信息会互相比较排除错误。损失函数是全连接输出层计算的均方根损失。随后我们会计算梯度错误。
- 错误会进行反向传播，以不断改进过滤器（权重）和偏差值。

